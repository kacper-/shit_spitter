Tonight, at Playground Global in Palo Alto, some very smart people who are building things you don’t understand yet will explain what’s coming. This is the final StrictlyVC event of 2025, and truly, the lineup is ridiculous.
The series has traveled around the globe under the auspices of TechCrunch. Steve Case rented a theater in Washington, D.C.; we talked to Greece’s prime minister in Athens; and Kirsten Green hosted us at the Presidio in San Francisco. The concept is always the same, though: bring together people who are working on genuinely important developments in a smaller setting, before everyone else figures out they’re important.
One of our favorite moments was when, in 2019, Sam Altman told a StrictlyVC crowd that OpenAI’s monetization strategy was basically “build AGI, then ask it how to make money.” Everyone laughed. He wasn’t joking.
This time, we’ve got Nicholas Kelez, a particle accelerator physicist who spent 20 years at the Department of Energy building things that shouldn’t be possible. Now he’s tackling semiconductor manufacturing’s biggest problem: Every advanced chip depends on $400 million machines that use lasers only one Dutch company knows how to make. (More galling to some: Americans invented the technology, then sold it to Europe.) Kelez is building the next generation in America using particle accelerator tech. It’s as nerdy as it sounds but also exceedingly important in this moment. There is also growing competition chasing after the same prize.
Then there’s Mina Fahmi, who’s made a ring that captures your whispered thoughts and turns them into text. Before you roll your eyes, know that he and co-founder Kirak Hong spent years at Meta working on this stuff after their company was acquired. The Stream Ring isn’t trying to be your friend — it’s trying to extend your brain. Backed by Toni Schneider, an operator who scaled WordPress in its earlier days, Sandbar just emerged from stealth and might well be onto something. (Schneider is a partner at True Ventures, whose other hardware bets have included Peloton, Ring, and Fitbit; he’s also coming to Palo Alto next week.)
We have Max Hodak — Science Corp. founder, Time magazine cover subject, and, earlier, Neuralink co-founder (along with Elon Musk) — who has already restored vision to dozens of blind people with retinal implants. Now he’s working on “biohybrid” brain-computer interfaces where chips seeded with stem cells grow into your brain tissue so paralyzed people can control devices with their thoughts. And that’s just the tip of the iceberg, as Hodak views it. In fact, he thinks 2035 is going to look wildly different from today, and he’s happy to share how.
Finally, we’re thrilled to welcome Chi-Hua Chien of Goodwater Capital and Elizabeth Weil of Scribble Ventures, two VCs who’ve backed Twitter, Spotify, TikTok, Slack, SpaceX, Figma, and Coinbase before they were household names. Chien runs Goodwater Capital; Weil founded Scribble Ventures after stints at Andreessen Horowitz and Twitter, made 100+ angel investments, and has a first fund showing 4x returns. (Her network is so good that it’s annoying.) Both think Silicon Valley is completely misreading the moment while everyone pours capital into enterprise AI, and they’ll explain why.
Playground Global is hosting, along with general partner Pat Gelsinger, the former CEO of Intel. There will be drinks, delicious food, and merriment; seating is limited, so if you want to get candid insights directly from these VC and tech heavy hitters, and make meaningful connections, then register for your seat before it’s gone. StrictlyVC events have limited seating.
Fintech company Marquis is notifying dozens of U.S. banks and credit unions that they had customer data stolen in a cyberattack earlier this year.
Details of the cyberattack emerged this week after Marquis filed data breach notices with several U.S. states confirming its August 14 incident as a ransomware attack.
Texas-based Marquis is a marketing and compliance provider that allows banks and other financial institutions to collect and visualize all of their customer data in one place. The company counts more than 700 banking and credit union customers on its website. As such, Marquis has access to and stores large amounts of data belonging to consumer banking customers across the United States.
At least 400,000 people are so far confirmed affected by the data breach, according to legally required disclosures filed in the states of Iowa, Maine, Texas, Massachusetts, and New Hampshire that TechCrunch has reviewed.
Texas has the largest number of state residents so far who had data stolen in the breach, affecting at least 354,000 people.
Marquis said in its notice with Maine’s attorney general that banking customers with the Maine State Credit Union accounted for the majority of its data breach notifications, or around one-in-nine people who are known to be affected throughout the state.
The number of individuals affected by the breach is expected to rise as more data breach notifications roll in from other states.
Marquis said the hackers stole customer names, dates of birth, postal addresses, and financial information, such as bank account, debit, and credit card numbers. Marquis said the hackers also stole customers’ Social Security numbers.
According to its most recent notices, Marquis blamed the ransomware attack on hackers who exploited a vulnerability in its SonicWall firewall. The vulnerability was considered a zero-day, meaning the flaw was not known to SonicWall or its customers before it was maliciously exploited by hackers.
Marquis did not attribute the ransomware attack to a particular group, but the Akira ransomware gang was reportedly behind the mass-hacks targeting SonicWall customers at the time.
TechCrunch asked Marquis if it is aware of the total number of people affected by the breach, and if Marquis received any communication from the hackers or if the company paid a ransom, but we did not hear back by the time of publication.
Two more nuclear companies have been awarded large grants by the Trump administration.
The Tennessee Valley Authority (TVA) and Holtec will each receive $400 million from the Department of Energy to build small modular reactors based on existing nuclear fission technology.
The TVA will build one 300-megawatt reactor from GE Vernova Hitachi in Tennessee, while Holtec will build two of its 300-megawatt reactors in Michigan.
Tech companies have warmed to nuclear power in recent years as their demand for electricity has grown alongside their AI ambitions.
The reactors to be built are considered Generation III+ designs, which are refinements of existing designs that have been in use for decades. By shrinking them down to “small modular” size, the hope is that costs will come down as parts are mass produced and engineering and construction crews become more familiar with building them.
To date, though, only two small modular reactors are operational, according to the World Nuclear Association.
Anthropic is prepping for an IPO that could come as early as 2026, the FT reports.
It has brought on law firm Wilson Sonsini to help kick off the process, and the company is tackling an internal checklist to prepare it for what could be one of the largest IPOs ever.
The company is also reportedly looking to raise a funding round that could value it at over $300 billion and has also been in talks with investment banks, though it has not chosen an underwriter, the FT reported. Anthropic last announced a $13 billion raise in September, giving it a $183 billion valuation. Wilson Sonsini has been an advisor to Anthropic since 2022.
This news comes as OpenAI, valued at $500 billion, is also reportedly testing the waters for an IPO and has started to prep itself for the process, though no listing date has been suggested, the Reuters reported.
Right on the heels of announcing Nova Forge, a service to train custom Nova AI models, Amazon Web Services (AWS) announced more tools for enterprise customers to create their own frontier models.
AWS announced new capabilities in Amazon Bedrock and Amazon SageMaker AI at its AWS re:Invent conference on Wednesday. These new capabilities are designed to make building and fine-tuning custom large language models (LLMs) easier for developers.
The cloud provider is introducing serverless model customization in SageMaker, which allows developers to start building a model without needing to think about compute resources or infrastructure, according to Ankur Mehrotra, general manager of AI platforms at AWS, in an interview with TechCrunch.
To access these serverless model-building capabilities, developers can either follow a self-guided point-and-click path or an agent-led experience where they can prompt SageMaker using natural language. The agent-led feature is launching in preview.
“If you’re a healthcare customer and you wanted a model to be able to understand certain medical terminology better, you can simply point SageMaker AI, if you have labeled data, then select the technique and then off SageMaker goes, and [it] fine tunes the model,” Mehrotra said.
This capability is available for customizing Amazon’s own Nova models and certain open source models (those with publicly available model weights), including DeepSeek and Meta’s Llama.
AWS is also launching Reinforcement Fine-Tuning in Bedrock that allows developers to choose either a reward function or a pre-set workflow, and Bedrock will run a model customization process automatically from start to finish.
Frontier LLMs — meaning the most advanced AI models — and model customization appear to be an area of focus for AWS at this year’s conference.
AWS announced Nova Forge, a service where AWS will build custom Nova models for its enterprise customers for $100,000 a year, during AWS CEO Matt Garman’s keynote on Tuesday.
“A lot of our customers are asking, ‘If my competitor has access to the same model, how do I differentiate myself?’” Mehrotra said. “‘How do I build unique solutions that are optimized, that optimize my brand, for my data, for my use case, and how do I differentiate myself?’ What we’ve found is that, the key to solving that problem is being able to create customized models.”
AWS has yet to gain a substantial user base for its AI models. A July survey from Menlo Ventures found that enterprises greatly prefer Anthropic, OpenAI, and Gemini to other models. However, the ability to customize and fine-tune these LLMs could start to give AWS a competitive advantage.
The rapid succession of robotaxi deployments from companies like Waymo and Zoox have people in the industry, once again, dreaming about how autonomous vehicles might change our daily lives. That includes driverless taxi rides, sure, but also headier ideas like sending an autonomous vehicle to fetch groceries or pick up dry cleaning.
If those things are ultimately going to happen, navigating the handoff moments — like where exactly a vehicle should stop to receive the groceries — will be a crucial piece of the puzzle. Palo Alto-based Autolane is trying to build that layer of infrastructure, and it now has $7.4 million in fresh funding to take on that goal.
Backed by VC firms like Draper Associates and Hyperplane, Autolane said it will start by coordinating pickup and drop-off points for companies that want to let robotaxis come onto their private property. The startup has signed a deal with Simon Property Group to coordinate driverless vehicle arrivals and departures at shopping centers owned by the real estate company in Austin, Texas and San Francisco, California.
This deal will include creating simple, physical infrastructure like signage (think: the many kinds of Uber and Lyft pickup and drop-off stanchions that decorate modern hotels and airports) and also software.
“I believe we are one of the first, let’s say, ‘application layer’ companies in autonomy,” Autolane co-founder and CEO Ben Seidl told TechCrunch in an exclusive interview. “We aren’t the fundamental models. We’re not building the cars. We’re not doing anything like that. We are simply saying, as this industry balloons rapidly and has exponential growth — as is already occurring this year and will occur for the next 10 years straight — someone is going to have to sit in the middle and orchestrate, coordinate, and kind of evaluate what’s going on.”
Autolane is starting with robotaxis in mind, but Seidl is clearly focused on the bigger-picture idea of applying his company’s tech to all kinds of tasks autonomous vehicles might be able to perform in the future. And he wants to move quickly with Autolane because, as he sees it, the startup doesn’t have “any direct competition” right now. He expects that to change soon.
Seidl said he was convinced there was a business here after buying a Tesla last year and using the company’s Full Self-Driving (Supervised) driver assistance software for the first time.
“As soon as my own personal car was driving me around town, pretty much flawlessly, I just — my head kind of exploded,” he said. “I was mostly enthralled by the idea that this was going to change logistics, retail, real estate, where we work, where we live, where we play, how we get around, what the price of movement of goods and services and people will be.”
Seidl cited the viral incident from earlier this year where a Waymo robotaxi got stuck navigating a Chick-fil-A drive-through in Santa Monica, California, as an example of the problem Autolane is trying to head off. In that case, the robotaxi had dropped off its passengers and then struggled to negotiate the fast food company’s notorious drive-through lanes. Seidl said by using Autolane software and designating an exact pick-up and drop-off location, problems like this can be avoided in the future.
“Someone has got to bring some order to this chaos, and the chaos is already starting,” he said.
Companies could surely do some of this work themselves, at least on the physical infrastructure side. It’s simply not that hard to make a sign.
“Anyone can do that,” Seidl said. “That’s not the case, though, for autonomy. Robotics need precise instructions and precise geolocation and technological communication. You can’t just put up a white sign with some black letters and hope for the best with 10 different types of robotics coming in.”
Instead, Seidl said the value of Autolane is in how it will integrate with the companies that own real estate as well as with the autonomous vehicle providers. That’s why the plan is to essentially build APIs for the physical locations so autonomous vehicle companies can receive these precise instructions. Businesses will have to “directly integrate into each one of these robotics companies, car companies, so that they follow your rules,” he said.
Seidl also said he explicitly does not want to work with cities or municipalities.
“We don’t work on public streets. We don’t work with public parking spots. We’re just providing these tools as kind of a B2B, hardware-enabled SAS solution so that Costco, or McDonald’s, or Home Depot, or, in our case, Simon Property Group, the world’s largest retail REIT [real estate investment trust] can begin to have what I like to refer to as ‘air traffic control for autonomous vehicles,’ meaning they know which ones are incoming and outgoing,” he said.
Waymo is adding another four cities to its growing list of robotaxi rollouts. The company announced Wednesday it has begun testing its autonomous vehicles (with a safety monitor) in Philadelphia, and that it will start manual driving to collect data in Baltimore, St. Louis, and Pittsburgh.
Waymo did not offer a timeline for when it plans to launch commercial services in those locations, nor do we know whether the Alphabet-owned company will partner with other companies to operate robotaxis in each one. That has been the move in cities like Atlanta and Austin, for example, where Waymo has partnered with Uber to advance its robotaxi rollout.
But the new locations join a list of over 20 cities where the company is either offering rides, prepping a commercial launch, or testing. Waymo is also now offering rides on freeways in Los Angeles, Phoenix, and the San Francisco Bay Area. The company plans to be doing one million rides per week by the end of 2026.
Waymo has done all this while claiming to be operating at a level five times safer than humans, according to data the company recently released.
But the expansion has not come without its issues. The National Highway Traffic Safety Administration is investigating how the company’s vehicles operate near school buses, after a Waymo was filmed driving around a stopped bus in Atlanta in September.
This week, Austin news outlet KXAN published a report showing Waymo’s vehicles have driven past school buses that were in the process of unloading or loading children multiple times — including after Waymo claims to have shipped software updates to address the problem.
Spotify Wrapped is back. After last year’s widely criticized flop that included an AI podcast as its highlight, the streamer’s highly anticipated annual review feature has returned to its roots. This year, Spotify is doubling down on what it knows works best: deep dives into your streaming data, creative experiences, messages from favorite artists, and other social features.
The company claims that Wrapped 2025 is its biggest, as it’s introducing nearly a dozen new features in addition to its old standbys, like top songs and artists. Plus, it’s offering more visibility into users’ data than in years past. For the first time, Spotify Wrapped is adding a live multiplayer feature to compare your listening data with friends.
Wrapped Party, Wrapped’s first live interactive experience, allows you to invite up to nine friends to compare listening stats.
Also new this year, your Top Songs Playlist will include the play counts for each of the top songs, so you can actually see how much time you spent with your favorite tracks.
Other standout features this year include an interactive Top Song Quiz, a Listening Age feature, and Wrapped Clubs, which match you to one of six unique listening styles.
The company believes these additions will not only bring back the personalized, engaging experience that users have long expected from Wrapped, but will take it a step further by making it more interactive than before.
In the Top Song Quiz, for instance, you can try to guess which top song soundtracked your year before seeing the results.
The new interactive Wrapped Party feature isn’t just about comparing the personal streaming data you’ve already received to your friends’ data, as that’s something people already do on social media. Instead, the feature presents unique data stories for your group, like who’s the “most obsessed fan,” the “early bird,” the most “picky listener,” or even something as nice as the “dinner table explainer,” meaning the person who listens to the most news podcasts.
Spotify says these awards update dynamically every time you join a Wrapped Party, so no two sessions are ever the same — even if you run through them again with the same group of friends.
The new Wrapped Clubs, meanwhile, will group you into one of half a dozen listening styles, like the “Soft Hearts Club,” the “Club Serotonin,” the “Full Charge Crew,” the “Cosmic Stereo Club,” and others. You’ll also receive a role in the club based on your listening data. You might be a club leader if your listening choices strongly match the club’s values, a scout if you’re always seeking out new releases, or an archivist if you listen to music from past eras.
Amazon announced a new product Tuesday called “AI Factories” that allows big corporations and governments to run its AI systems in their own data centers. Or as AWS puts it: Customers supply the power and the data center, and AWS plunks in the AI system, manages it, and can tie it into other AWS cloud services.
The idea is to cater to companies and governments concerned with data sovereignty, or absolute control over their data so it can’t wind up in a competitor’s or foreign adversary’s hands. An on-prem AI Factory means not sending their data to a model maker and not even sharing the hardware.
If that product name sounds familiar, it should. That’s what Nvidia calls its hardware systems that are chock-full of tools needed to run AI, from its GPU chips to its networking tech. This AWS AI Factory is, in fact, a collaboration with Nvidia, both companies say.
In this case, the AWS Factory will use a combination of AWS and Nvidia technology. Companies that deploy these systems can opt for Nvidia’s latest Blackwell GPUs or Amazon’s new Trainium3 chip. It uses AWS’ homegrown networking, storage, databases, and security and can tap into Amazon Bedrock — the AI model selection and management service, and AWS SageMaker AI, the model building and training tool.
Interestingly, AWS is far from the only giant cloud provider installing Nvidia AI Factories. In October, Microsoft showed off its first of many-to-come AI Factories rolling out into its global data centers to run OpenAI workloads. Microsoft didn’t announce at the time that these extreme machines would be available for private clouds. Instead, Microsoft highlighted how it was leaning on a host of Nvidia AI Factory data center tech to build and connect its new “AI Superfactories,” aka new state-of-the-art data centers being built in Wisconsin and Georgia.
Last month, Microsoft also outlined the data centers and cloud services that would be built in local countries to address the data sovereignty issue. To be fair, its options also include “Azure Local,” Microsoft’s own managed hardware that could be installed on customer sites.
Still, it is a bit ironic that AI is causing the biggest cloud providers to invest so heavily in corporate private data centers and hybrid clouds like it’s 2009 all over again.
Tonight, at Playground Global in Palo Alto, some very smart people who are building things you don’t understand yet will explain what’s coming. This is the final StrictlyVC event of 2025, and truly, the lineup is ridiculous.
The series has traveled around the globe under the auspices of TechCrunch. Steve Case rented a theater in Washington, D.C.; we talked to Greece’s prime minister in Athens; and Kirsten Green hosted us at the Presidio in San Francisco. The concept is always the same, though: bring together people who are working on genuinely important developments in a smaller setting, before everyone else figures out they’re important.
One of our favorite moments was when, in 2019, Sam Altman told a StrictlyVC crowd that OpenAI’s monetization strategy was basically “build AGI, then ask it how to make money.” Everyone laughed. He wasn’t joking.
This time, we’ve got Nicholas Kelez, a particle accelerator physicist who spent 20 years at the Department of Energy building things that shouldn’t be possible. Now he’s tackling semiconductor manufacturing’s biggest problem: Every advanced chip depends on $400 million machines that use lasers only one Dutch company knows how to make. (More galling to some: Americans invented the technology, then sold it to Europe.) Kelez is building the next generation in America using particle accelerator tech. It’s as nerdy as it sounds but also exceedingly important in this moment. There is also growing competition chasing after the same prize.
Then there’s Mina Fahmi, who’s made a ring that captures your whispered thoughts and turns them into text. Before you roll your eyes, know that he and co-founder Kirak Hong spent years at Meta working on this stuff after their company was acquired. The Stream Ring isn’t trying to be your friend — it’s trying to extend your brain. Backed by Toni Schneider, an operator who scaled WordPress in its earlier days, Sandbar just emerged from stealth and might well be onto something. (Schneider is a partner at True Ventures, whose other hardware bets have included Peloton, Ring, and Fitbit; he’s also coming to Palo Alto next week.)
We have Max Hodak — Science Corp. founder, Time magazine cover subject, and, earlier, Neuralink co-founder (along with Elon Musk) — who has already restored vision to dozens of blind people with retinal implants. Now he’s working on “biohybrid” brain-computer interfaces where chips seeded with stem cells grow into your brain tissue so paralyzed people can control devices with their thoughts. And that’s just the tip of the iceberg, as Hodak views it. In fact, he thinks 2035 is going to look wildly different from today, and he’s happy to share how.
Finally, we’re thrilled to welcome Chi-Hua Chien of Goodwater Capital and Elizabeth Weil of Scribble Ventures, two VCs who’ve backed Twitter, Spotify, TikTok, Slack, SpaceX, Figma, and Coinbase before they were household names. Chien runs Goodwater Capital; Weil founded Scribble Ventures after stints at Andreessen Horowitz and Twitter, made 100+ angel investments, and has a first fund showing 4x returns. (Her network is so good that it’s annoying.) Both think Silicon Valley is completely misreading the moment while everyone pours capital into enterprise AI, and they’ll explain why.
Nuclear startup Antares said Tuesday it has raised $96 million in Series B funding as it pursues its small modular reactor design.
The round, which was led by Shine Capital with participation from Alt Capital, Caffeinated, FiftyThree Stations, Industrious, and others, consists of $71 million in equity and $25 million in debt.
Antares says it is targeting commercial, defense, and space-based applications with its R1 microreactor, which will produce between 100 kilowatts and 1 megawatt of electricity. The design uses TRISO fuel, which in Antares case is spheres of carbon- and ceramic-coated uranium embedded in graphite.
The startup is one of several companies that have benefited recently from renewed interest in nuclear power over the last six months.
Last week, Amazon-backed X-energy said it had raised a $700 million Series D round, which came on the heels of an upsized $700 million Series C that closed in February. The company is also designing a reactor around TRISO fuel. Deep Fission, which had struggled to raise money as recently as April, went public in a $30 million reverse merger in September.
Aalo Atomics raised $100 million in August to build a demonstration data center powered by a microreactor, and in June, Nvidia contributed to a $650 million round for TerraPower, a small modular reactor startup also backed by Bill Gates.
Big nuclear plants have been given a second chance, too.
Earlier this month, Microsoft partner Constellation Energy received a $1 billion loan from the Department of Energy to restart a reactor at Three Mile Island by 2028. That project is expected to cost $1.6 billion to refurbish the reactor that was idled in 2019. In October, Google said it would work with NextEra Energy to reopen a nuclear power plant in Iowa that was damaged during a torrential downpour in 2020.
Earlier this summer, Amazon bought 1.92 gigawatts of generating capacity from a Talen Energy nuclear plant in Pennsylvania. Meta also said in June it would buy the clean energy attributes from a Constellation Energy nuclear power plant in Illinois.
And while big nuclear has been a major beneficiary, the Trump administration is bullish on small nuclear’s potential to revive the industry’s fortunes in the coming decade.
In August, Antares was named one of 11 participants in the Department of Energy’s reactor pilot program, which aims to have at least three of those begin operation by July 4, 2026, a timeline that’s significantly faster than the nuclear industry is accustomed to.
Antares has said it aims to demonstrate its reactor for the DOE next year and is planning to turn on its full-power reactor sometime in 2027.
New data shows ChatGPT’s growing influence as a referrer to e-commerce websites, as well as how small its slice of this market is currently.
According to a new analysis by mobile app insights provider Apptopia, ChatGPT referrals to retailer mobile apps increased 28% year-over-year over the Black Friday holiday shopping weekend, running from Thanksgiving Day on Thursday through Sunday.
However, the use of ChatGPT may not be benefiting smaller retailers as much as it’s helping to further entrench the e-commerce giants Amazon and Walmart. This year, Amazon’s share of ChatGPT referrals grew to 54%, up from 40.5% in 2024. Walmart’s share, meanwhile, increased from 2.7% last year to now 14.9%.
The data was collected by Apptopia’s U.S. panel, which is based on observed consumer activity on mobile devices. As it’s not first-party data, its figures are only estimates. For this analysis, the firm defined a referral session as a retail mobile app session that directly followed (within 30 seconds) a ChatGPT session.
Despite the big jump from 2024, consumers’ use of AI chatbots to find e-commerce deals is still a small sliver of the overall referral market, Apptopia noted. Last year, ChatGPT’s referrals to e-commerce apps were only 0.64% of all ChatGPT sessions on Black Friday, and that figure only grew to 0.82% this year.
In this case, a referral session was anytime ChatGPT either gave the searcher a shopping idea or the user clicked a link directly from their chat session that brought them to the retail app.
Apptopia isn’t the only firm digging into how AI is impacting e-commerce during the busy holiday shopping season. Adobe also reported this week that AI traffic to U.S. retail sites (measured by shoppers clicking on a link) increased by 805% year-over-year on Black Friday, and those who landed on a retail site from an AI chatbot were 38% more likely to make a purchase.
In addition, Adobe said that AI traffic to U.S. retail sites on Cyber Monday increased by 670%. In the holiday shopping season so far (November 1 to December 1), AI traffic is up 760%, it noted.
Amazon Web Services is rolling out a slate of new homegrown AI models and a service for enterprise customers to build their own custom versions. The cloud provider launched Nova 2, a fleet of four new AI models to its Nova model family, during AWS CEO Matt Garman’s AWS re:Invent keynote on Tuesday.
The first version of AWS Nova was announced last year at the company’s annual tech conference. At the time, the company released four text-generating models and one image-generating model. This year, AWS is giving the models an upgrade and launching an accompanying service.
“The momentum has been really fantastic,” Garman said during his Tuesday keynote. “Nova has been, has grown to be used by tens of thousands of customers today, everyone from marketing giants to tech leaders like Infosys or Blue Origin or Robinhood to innovative startups like NinjaTech AI and today, we’re making Nova even better.”
The four new models include Nova 2 Lite, a more cost-effective reasoning model. Reasoning AI models “think” before they respond and can process text, images, and videos to generate text that’s meant for everyday tasks. Nova 2 Pro is a reasoning agent that can process text, images, videos and speech that is designed for “highly complex tasks” like coding.
Nova 2 Sonic is a new speech-to-speech model to be used for conversational AI. Nova 2 Omni is a multimodal reasoning and generation model that can process images, text, video and speech input, and produce both text and images.
Alongside the model upgrades, AWS also announced a new service called Nova Forge which allows AWS cloud customers to build their own frontier version of AWS Nova models called Novellas for $100,000 a year, according to CNBC reporting. This service allows enterprises to access pre-trained, mid-trained or post-trained models for companies to then train on their own proprietary data.
Garman said this will be able to solve some of the problems that arise when enterprises try to incorporate their own data into already-trained AI models.
“The more you customize models, the more you add a bunch of data in post training, these models tend to forget some of that interesting stuff that it learned earlier the core reasoning,” Garman said. “It’s a little bit like humans trying to learn new language. When you start when you’re really young, it’s actually relatively easy to pick up, but when you try to, you learn a new language later in life, it’s actually much, much harder. Model training is kind of like this too.”
Companies including Reddit, Sony and Booking.com are early Nova Forge customers.
As Discord prepares for a potential IPO, the platform is launching new commerce features to enhance the gaming experience for users while also generating new revenue streams for developers.
Announced on Tuesday, the features allow users to purchase digital game items directly within Discord, eliminating the need to leave the platform. Users can also create wishlists for game items and send in-game items as gifts through direct messages.
If Discord becomes a public company, it will face financial scrutiny, so these additions also present a new monetization opportunity for both Discord and game developers. By enabling developers to sell digital goods directly on Discord, the platform helps them reach a wider audience beyond their own communities, potentially boosting revenue.
The initial rollout of these features is in partnership with the popular video game Marvel Rivals, which now has a dedicated store page within the game’s official Discord server.
Marvel Rivals is a smart choice for this launch, as it garnered 10 million players within 72 hours of its release last year, generated over $100 million in its first month, and has built a community of more than 4 million members on Discord.
Players can now browse and purchase in-game items directly from the Marvel Rivals server, which includes items such as bundles, costumes, emotes, and emojis.
Additionally, users can create wishlists that friends can view and purchase as gifts. With the holiday season approaching, this feature is particularly timely, as it simplifies gift-giving for those looking to buy for gamer friends or family members. Plus, the ability to gift in-game items through DMs allows users to send gifts to friends even if they don’t play Marvel Rivals themselves.
It’s that time of year when companies are rolling out their Spotify Wrapped-like end-of-year recaps, letting users revisit the content they engaged with the most. While YouTube has offered a YouTube Music recap for the past few years, the platform announced on Tuesday that it’s now launching a separate experience for videos watched on the main service.
YouTube Recap features up to 12 personalized cards that highlight a user’s top channels, interests, the evolution of their viewing habits, and personality-type assignment based on their watching preferences.
For instance, the “Skill Builder” personality type goes to users who are drawn to content that helps develop skills, while “Sunshiners” gravitate toward content that spreads positivity. “Trailblazers” watch content that’s original and challenges the norm.
Other personality types include the “Wonder Seeker,” the “Connector,” and the “Dreamer,” among others.
Users will also be able to see their top artists and songs of the year, but they can get deeper insights in the YouTube Music app with their annual YouTube Music Recap, which started rolling out last week.
Recap is available starting today for YouTube users in North America, with a global rollout coming this week. Users can find their Recap directly on the YouTube homepage or under the “You” tab. Recaps are accessible on mobile devices and desktop.
YouTube says the new feature was requested by users and that it conducted over 50 different concept tests before landing on the final product.
Alongside the launch of Recap, YouTube also released trend charts showcasing the top creators, podcasts, and songs of the year.
MrBeast took the No. 1 spot for top creator for the sixth year in a row. The top podcast spot went to “The Joe Rogan Experience,” while Bruno Mars and Lady Gaga took the No. 1 spot for top song with “Die with a Smile.”
YouTube Recap arrives the same day as Apple Music’s Replay and Amazon Music’s 2025 Delivered. Spotify has yet to release its highly anticipated Wrapped, suggesting that other companies are looking to get the jump on social media sharing.
Amazon has announced it’s launching a new service that completes deliveries in 30 minutes or less in Seattle and Philadelphia. The new “ultra-fast” delivery option will allow Amazon to better compete with services like DoorDash, Uber Eats, and Instacart.
Customers will be able to order a range of different items, including milk, eggs, fresh produce, toothpaste, cosmetics, pet treats, diapers, paper products, electronics, seasonal items, over-the-counter medicines, chips, dips, and more, according to the company.
Prime members can choose the fast delivery option for a $3.99 fee per order, while non-Prime members will have to pay $13.99. Orders below $15 will include a small-basket fee of $1.99.
Customers in Seattle and Philadelphia can now check the Amazon app and homepage and look for the “30-Minute Delivery” option in the navigation bar to see if it’s available in their area.
After placing an order, customers can track their deliveries and tip drivers through the app.
“Amazon is utilizing specialized smaller facilities designed for efficient order fulfillment, strategically placed close to where Seattle- and Philadelphia-area customers live and work,” Amazon explained in a blog post. “This approach prioritizes the safety of employees picking and packing orders, reduces the distance delivery partners need to travel, and enables faster delivery times.”
The move follows Amazon’s launch of a 15-minute delivery service in the United Arab Emirates in October. The company said at the time that some customers received their orders in as little as six minutes.
The launch of the new service marks Amazon’s latest effort to enter the fast delivery market in the United States. In 2014, the e-commerce giant introduced a “Prime Now” service that offered one-hour deliveries, but the company discontinued it in 2021.
Amazon has been working to expand its delivery options and announced in June that it plans to invest more than $4 billion to triple the size of its delivery network by 2026.
French AI startup Mistral launched its new Mistral 3 family of open-weight models on Tuesday, a launch that aims to prove it can lead in making AI publicly available and serve business clients better than Big Tech rivals.

The 10-model release includes a large frontier model with multimodal and multilingual capabilities and nine smaller offline-capable, fully customizable models.
The launch comes as Mistral, which develops open-weight language models and Europe-focused AI chatbot Le Chat, has appeared to be playing catch up with some of Silicon Valley’s closed-source frontier models. Open-weight models release their model weights publicly so anyone can download and run them. Meanwhile, closed-source models, like OpenAI’s ChatGPT, keep their weights proprietary and only provide access through APIs or controlled interfaces.
The two-year-old startup, founded by former DeepMind and Meta researchers, has raised about $2.7 billion to date at a $13.7 billion valuation — peanuts compared to the numbers that competitors like OpenAI ($57 billion raised at a $500 billion valuation) and Anthropic ($45 billion raised at a $350 billion valuation) are pulling.
But Mistral is trying to prove that bigger isn’t always better — especially for enterprise use cases.
“Our customers are sometimes happy to start with a very large [closed] model that they don’t have to fine-tune … but when they deploy it, they realize it’s expensive, it’s slow,” Guillaume Lample, co-founder and chief scientist at Mistral, told TechCrunch. “Then they come to us to fine-tune small models to handle the use case [more efficiently].”
“In practice, the huge majority of enterprise use cases are things that can be tackled by small models, especially if you fine-tune them,” Lample continued.
Initial benchmark comparisons, which place Mistral’s smaller models well behind its closed-source competitors, can be misleading, Lample said. Large closed-source models may perform better out-of-the-box, but the real gains happen when you customize.
Mistral’s large frontier model, dubbed Mistral Large 3, catches up to some of the important capabilities that larger closed-source AI models like OpenAI’s GPT-4o and Google’s Gemini 2 boast, while also trading blows with several open-weight competitors. Large 3 is among the first open frontier models with multimodal and multilingual capabilities all in one, putting it on par with Meta’s Llama 3 and Alibaba’s Qwen3-Omni. Many other companies currently pair impressive large language models with separate smaller multi-modal models, something Mistral has done previously with models like Pixtral and Mistral Small 3.1.
Large 3 also features a “granular Mixture of Experts” architecture with 41 billion active parameters and 675 billion total parameters, enabling efficient reasoning across a 256,000 context window. This design delivers both speed and capability, allowing it to process lengthy documents and function as an agentic assistant for complex enterprise tasks. Mistral positions Large 3 as suitable for document analysis, coding, content creation, AI assistants, and workflow automation.
With its new family of small models, dubbed Ministral 3, the company is making the bold claim that smaller models aren’t just sufficient – they’re superior.
The lineup includes nine distinct, high-performance dense models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants: Base (the pre-trained foundation model), Instruct (chat-optimized for conversation and assistant-style workflows), and Reasoning (optimized for complex logic and analytical tasks).
Mistral says this range gives developers and businesses the flexibility to match models to their exact performance, whether they’re after raw performance, cost efficiency, or specialized capabilities. The company claims Ministral 3 scores on par or better than other open-weight leaders while being more efficient and generating fewer tokens for equivalent tasks. All variants support vision, handle 128,000-256,000 context windows, and work across languages.
A major part of the pitch is practicality. Lample emphasizes that Ministral 3 can run on a single GPU, making it deployable on affordable hardware — from on-premise servers to laptops, robots, and other edge devices that may have limited connectivity. That matters not only for enterprises keeping data in-house, but also for students seeking feedback offline or robotics teams operating in remote environments. Greater efficiency, Lample argues, translates directly to broader accessibility.
“It’s part of our mission to be sure that AI is accessible to everyone, especially people without internet access,” he said. “We don’t want AI to be controlled by only a couple of big labs.”
Some other companies are pursuing similar efficiency trade-offs: Cohere’s latest enterprise model, Command A, also runs on just two GPUs, and its AI agent platform North can run on just one GPU.
That sort of accessibility is driving Mistral’s growing physical AI focus. Earlier this year, the company began working to integrate its smaller models into robots, drones, and vehicles. Mistral is collaborating with Singapore’s Home Team Science and Technology Agency (HTX) on specialized models for robots, cybersecurity systems, and fire safety; with German defense tech startup Helsing on vision-language-action models for drones; and with automaker Stellantis on an in-car AI assistant.
For Mistral, reliability and independence are just as critical as performance.
The Trump administration has agreed to inject up to $150 million into xLight, a semiconductor startup developing advanced chip-making technology, marking the third time the U.S. government has taken an equity position in a private startup and further expanding a controversial strategy that has put Washington on the cap tables of American companies.
The Wall Street Journal reported Monday that the Commerce Department will provide the funding to xLight in exchange for an equity stake that will likely make the government the startup’s largest shareholder. The deal uses funding from the 2022 Chips and Science Act and represents the first Chips Act award in President Trump’s second term, though it remains preliminary and subject to change.
Previous government equity investments under the Trump administration include publicly traded companies Intel, MP Materials, Lithium Americas, and Trilogy Metals. Two rare earths startups also secured funding in exchange for equity from the Commerce Department last month.
You can imagine how this is all going over in Silicon Valley, where the libertarian ethos runs deep. At TechCrunch’s signature Disrupt event back in October, Sequoia Capital’s Roelof Botha jokingly offered what might be the understatement of the year when asked about the trend: “[Some] of the most dangerous words in the world are: ‘I’m from the government, and I’m here to help.’”
Other VCs have similarly expressed concerns, if quietly, about what it means when their portfolio companies are suddenly competing against startups backed by the U.S. Treasury, or even when they find themselves sitting across the table from government representatives at board meetings.
The four-year-old, Palo Alto, California, company at the center of this particular experiment is trying to do something genuinely audacious in semiconductor manufacturing. XLight wants to build particle accelerator-powered lasers — machines the size of a football field, mind you — that would create more powerful and precise light sources for making chips.
If it works, it could challenge the near-total dominance of ASML, the Dutch giant that has been publicly traded since 1995 and currently enjoys an absolute monopoly on extreme ultraviolet lithography machines. (Its shares have surged 48.6% this year.)
The CEO of xLight is Nicholas Kelez, a quantum computing and government labs veteran who presumably knows his way around a particle accelerator. Helping this venture as executive chairman is Pat Gelsinger, the former Intel CEO who was shown the door late last year after his ambitious manufacturing revival plans failed to materialize.
“I wasn’t done yet,” Gelsinger — who is also a general partner at Playground Global, which led the startup’s $40 million funding round this summer — told the Journal, adding that the effort is “deeply personal” to him.
Indeed, xLight doesn’t just want to compete with ASML but to go much further. While ASML’s machines work at wavelengths around 13.5 nanometers, xLight is targeting 2 nanometers. Gelsinger claims the technology could boost wafer processing efficiency by 30% to 40% while using far less energy.
As it happens, both Kelez and Gelsinger will be holding forth at TechCrunch’s StrictlyVC event on Wednesday night in Palo Alto, where the government’s backing will no doubt come up. (You can still nab a seat here.)
Commerce Secretary Howard Lutnick, for his part, insists this is all in service of national security and technological leadership, saying the partnership could “fundamentally rewrite the limits of chipmaking.” Critics will continue to question whether taxpayer-funded equity stakes represent visionary industrial policy or state capitalism with a patriotic sheen, though even skeptics acknowledge the geopolitical reality.
At least Botha, who described himself at Disrupt as a “sort of libertarian, free market thinker by nature,” conceded that industrial policy has its place when national interests demand it. “The only reason the U.S. is resorting to this is because we have other nation-states with whom we compete who are using industrial policy to further their industries that are strategic and maybe adverse to the U.S. in long-term interests.”
In a carefully worded announcement on Monday, Apple said John Giannandrea, who has been the company’s AI chief since 2018, is “stepping down” to, well, not work at Apple anymore. He’ll stick around through spring as an adviser.
His replacement is Amar Subramanya, a highly regarded Microsoft executive who spent 16 years at Google, most recently leading engineering for the Gemini Assistant. It’s a savvy hire, given that Subramanya knows the competition intimately.
The move is being characterized as a shake-up. It was seemingly inevitable in retrospect. Apple Intelligence, the company’s answer to the ChatGPT moment, has been stumbling since its October 2024 launch. Reviews have ranged from “underwhelming” to outright alarmed.
Its first months were some of the roughest. A notification summary feature meant to condense multiple alerts into digestible snippets generated a series of embarrassing, untrue headlines in late 2024 and early 2025. Among other missteps, the BBC complained twice after Apple Intelligence falsely reported that Luigi Mangione, the man accused of killing UnitedHealthcare CEO Brian Thompson, had shot himself (he hadn’t) and that a darts player, Luke Littler, won a championship before the final even began.
Then there was Siri’s promised overhaul, which became a black eye for Apple.
A Bloomberg investigation published in May revealed the depths of Apple’s AI struggles. For instance, when Craig Federighi, Apple’s software chief, tested the new Siri on his own phone just weeks before its planned launch in April, he was dismayed to find that many of the features the company had been touting didn’t work. The launch was delayed indefinitely, triggering class-action lawsuits from iPhone 16 buyers who’d been promised an AI-powered assistant.
By that point, Giannandrea had already been sidelined, according to Bloomberg. The news organization reported that Tim Cook had stripped Siri from Giannandrea’s oversight entirely back in March, handing it to Vision Pro creator Mike Rockwell. Apple removed its secretive robotics division from Giannandrea’s control, too.
Bloomberg’s investigation painted a picture of organizational dysfunction, with weak communication between AI and marketing teams, budget misalignments, and a leadership crisis severe enough that some employees had taken to mockingly calling Giannandrea’s group “AI/MLess.” The report also documented an exodus of AI researchers to competitors, including OpenAI, Google, and Meta.
Apple is reportedly now leaning on Google’s Gemini to power the next version of Siri, an astonishing and, presumably, humbling twist considering the intense rivalry between the two companies that dates back more than 15 years, across mobile operating systems, app stores, browsers, maps, cloud services, smart home devices, and now AI.
Giannandrea came to Apple from Google, where he ran Machine Intelligence and Search. At Apple, he oversaw the AI strategy, machine learning infrastructure, and Siri development.
Now Subramanya inherits those responsibilities, reporting to Federighi with a clear mandate to help Apple catch up in AI.
It’s an interesting moment for the company. While competitors have been pouring billions of dollars into massive AI data centers, Apple has focused on processing AI tasks directly on users’ devices using its custom Apple Silicon chips, a privacy-first approach that avoids collecting user data. (When more complex requests require cloud processing, Apple routes them through Private Cloud Compute, servers that promise to process data temporarily and delete it immediately.)
Whether that philosophy pays off or whether it has permanently left Apple behind is an outstanding question. Apple’s approach comes with clear trade-offs. Among them, on-device models are smaller and less capable than the massive models running in competitors’ data centers, and Apple’s reluctance to collect user data has left its researchers training models on licensed and synthetic data rather than the giant troves of real-world information that fuel its rivals’ systems.
Nvidia announced new infrastructure and AI models on Monday as it works to build the backbone technology for physical AI, including robots and autonomous vehicles that can perceive and interact with the real world.
The semiconductor giant announced Alpamayo-R1, an open reasoning vision language model for autonomous driving research at the NeurIPS AI conference in San Diego, California. The company claims this is the first vision language action model focused on autonomous driving. Visual language models can process both text and images together, allowing vehicles to “see” their surroundings and make decisions based on what they perceive.
This new model is based on Nvidia’s Cosmos-Reason model, a reasoning model that thinks through decisions before it responds. Nvidia initially released the Cosmos model family in January 2025. Additional models were released in August.
Technology like the Alpamayo-R1 is critical for companies looking to reach level 4 autonomous driving, which means full autonomy in a defined area and under specific circumstances, Nvidia said in a blog post.
Nvidia hopes that this type of reasoning model will give autonomous vehicles the “common sense” to better approach nuanced driving decisions like humans do.
This new model is available on GitHub and Hugging Face.
Alongside the new vision model, Nvidia also uploaded new step-by-step guides, inference resources, and post-training workflows to GitHub — collectively called the Cosmos Cookbook — to help developers better use and train Cosmos models for their specific use cases. The guide covers data curation, synthetic data generation, and model evaluation.
These announcements come as the company is pushing full-speed into physical AI as a new avenue for its advanced AI GPUs.
Nvidia’s co-founder and CEO Jensen Huang has repeatedly said that the next wave of AI is physical AI. Bill Dally, Nvidia’s chief scientist, echoed that sentiment in a conversation with TechCrunch over the summer, emphasizing physical AI in robotics.
“I think eventually robots are going to be a huge player in the world and we want to basically be making the brains of all the robots,” Dally said at the time. “To do that, we need to start developing the key technologies.”
Planned data center construction shows no signs of fading, with new additions to require 2.7x — nearly triple — the sector’s current demand for electricity over the next decade, according to a new report from BloombergNEF.
By 2035, data centers will draw 106 gigawatts, up sharply from the 40 gigawatts they use today. Much of that growth will occur in more rural areas as facilities grow in size and as sites near urban areas become scarce, BloombergNEF said.
Driving part of the growth is the sheer scale of planned data centers. Today, only 10% of data centers draw more than 50 megawatts of electricity, but over the next decade, the average new facility will draw well over 100 megawatts. The biggest sites help skew the data: Nearly a quarter will be larger than 500 megawatts, and a few will exceed 1 gigawatt.
At the same time, the utilization rate for all data centers is expected to grow from 59% to 69% as AI training and inference grows to nearly 40% of total data center compute.
In some ways, the findings in the new report aren’t surprising. AI companies have been racing to build more powerful data centers, helping to drive global investment in the facilities up to $580 billion this year. That’s more than the world spends finding new supplies of oil.
Still, the new report shows just how quickly the landscape is changing. It is a sharp revision upwards from a document the group published in April. The upswing was driven by a surge in new projects that have been announced since then. “With an average seven-year timeline for projects to come online, developments in earlier stages affect the tail end of our forecast the most,” the new report said.
Early-stage projects have more than doubled between early 2024 and early 2025, though those are distinct from projects that have been committed or are currently under construction.
Much of that new capacity is being planned for Virginia, Pennsylvania, Ohio, Illinois, and New Jersey. They lie within a region known to industry experts at the PJM Interconnection, a regional transmission organization that’s tasked with operating the electrical grid in those states and others, including Delaware, West Virginia, and parts of Kentucky and North Carolina. Texas’s Ercot grid will see a large number of additions, too.
The report arrives as the PJM Interconnection is under scrutiny from its independent monitor, Monitoring Analytics. The group filed a complaint with the Federal Energy Regulatory Commission (FERC) saying that PJM has the authority to authorize new data center connections only when its grid has adequate capacity.
“As part of its obligation to maintain reliability, PJM has the authority to require large new data center loads to wait to be added to the system until the loads can be served reliably,” Monitoring Analytics wrote. “PJM has the authority to create a load queue.”
What’s more, data centers are responsible for today’s high electricity prices within the region, the organization said.
“PJM’s failure to clarify and enforce its existing rules and to protect reliable and affordable service in PJM is unjust and unreasonable,” it said.
A coalition of law enforcement agencies coordinated by Europol announced Monday the shuttering of cryptocurrency laundering service Cryptomixer.
Europol confirmed the seizure in a press release, where it called Cryptomixer “the platform of choice for cybercriminals seeking to launder illegal proceeds from a variety of criminal activities, such as drug trafficking, weapons trafficking, ransomware attacks, and payment card fraud.”
Since 2016, Europol said, Cryptomixer facilitated the laundering of 1.3 billion euros ($1.5 billion) in Bitcoin.
Hackers and other criminals use laundering services such as Cryptomixer to obfuscate and hide the provenance of their cryptocurrency. By design, cryptocurrencies such as Bitcoin and Ethereum are built on public blockchains that allow law enforcement, as well as blockchain intelligence firms such as Chainalysis and Elliptic, to follow the money over time.
Authorities said they seized $25 million euros ($29 million) in Bitcoin, along with three servers, 12 terabytes of data, and the official domain cryptomixer.io, which now displays the customary law enforcement seizure splash page.
According to Europol, the site “facilitated the obfuscation of criminal funds for ransomware groups, underground economy forums and dark web markets,” and claimed its software “blocked the traceability of funds on the blockchain.”
“Deposited funds from various users were pooled for a long and randomised period before being redistributed to destination addresses, again at random times. As many digital currencies provide a public ledger of all transactions, mixing services make it difficult to trace specific coins, thus concealing the origin of cryptocurrency,” Europol said.
Cryptomixer offered customers anonymity, such as providing cover for cybercriminals who wanted to launder their crypto before taking the funds to legitimate cryptocurrency exchanges. Europol said the “cleaned” cryptocurrency could be swapped for other cryptocurrencies or fiat cash.
Over the years, authorities have shut down or sanctioned several similar services, such as Tornado Cash, ChipMixer, and others.
With AI igniting an investor frenzy, every month, more startups obtain unicorn status.
Using data from Crunchbase and PitchBook, TechCrunch tracked down the VC-backed startups that became unicorns so far this year. While most are AI-related, a surprising number are focused in other industries like satellite space companies Loft Orbital and blockchain-based trading site Kalshi.
This list will be updated throughout the year, so check back and see the latest powerhouse startups that are now worth over $1 billion.
November
Genspark — $1.25 billion: This company builds AI agents to help automate tasks. It raised a $275 million Series B, giving it a $1.25 billion valuation, according to Forbes. Backers include Emergence Capital Partners and LV Technology Ventures. The company was founded in 2023.
Gamma — $2.1 billion: This company, which creates AI-generated visuals, such as websites, announced a $68 million Series B led by a16z, giving it a $2.1 billion valuation, TechCrunch previously reported. The company launched its first product in 2022.
James Cameron’s movies are often at the cutting edge of visual effects technology — especially the “Avatar” films, with their heroic blue Na’vi characters brought to life through performance capture.
But that doesn’t make Cameron a fan of generative AI.
In a CBS Sunday Morning interview tied to the upcoming release of “Avatar: Fire and Ash,” the director acknowledged that performance capture (where an actor’s performance is recorded as a template for digital artists) can sound similar to GenAI. But in reality, he said it’s “the opposite.”
“For years, there was this sense that, ‘Oh they’re doing something strange with computers, and they’re replacing actors,’” Cameron said. “When in fact, once you really drill down and you see what we’re doing, it’s a celebration of the actor-director moment.”
Indeed, the CBS segment shows members of the “Avatar” cast performing their underwater scenes in a 250,000-gallon water tank.
“Go to the other end of the spectrum and you’ve got generative AI, where they can make up a character, they can make up an actor, they can make up a performance from scratch with a text prompt,” Cameron added. “No, that’s horrifying … That’s exactly what we’re not doing.”
David Sacks’ role as President Donald Trump’s artificial intelligence and crypto czar could work out very well for his investments, as well as his friends, according to a new report The New York Times.
However, Sacks fired back in a post on X, in which he described a five-month reporting process in which accusations were “debunked in detail.”
“Today they evidently just threw up their hands and published this nothing burger,” Sacks said. “Anyone who reads the story carefully can see that they strung together a bunch of anecdotes that don’t support the headline.”
This isn’t the first time critics have suggested that there may be conflicts of interest between Sacks’ political role and his investments. For example, Senator Elizabeth Warren — a Democrat from Massachusetts — said earlier this year that Sacks “simultaneously leads a firm invested in crypto while guiding the nation’s crypto policy,” an “explicit conflict of interest” that would “normally” be prohibited under federal law.
But the NYT’s story (under the headline “Silicon Valley’s Man in the White House Is Benefiting Himself and His Friends,” and credited to five bylined reporters) seems to offer a more comprehensive view, with an analysis of his financial disclosures suggesting that among Sacks’ 708 tech investments, 449 are AI companies that could benefit from the policies he supports.
Sacks has received two White House ethics waivers declaring he would sell most of his crypto and AI assets. However, the NYT said his public ethics filings do not disclose the remaining value of his crypto and AI investments, nor do they say when he sold off the assets he divested.
Kathleen Clark, a Washington University law professor specializing in government ethics, made similar points in July after reviewing Sacks’ crypto waiver, telling TechCrunch, “This is graft.”
The NYT also said that Sacks’ filings classify hundreds of investments as hardware or software, rather than AI, while the companies pitch themselves as AI businesses in their marketing.
To illustrate Sacks’ “intertwined interests,” the NYT pointed to the White House summit in July where Trump unveiled his AI roadmap — White House chief of staff Susie Wiles reportedly stepped in to prevent the All-In podcast (which Sacks co-hosts) from being the only host of the event. And All-In asked potential sponsors to pay $1 million for access to a private reception and other events, the NYT claimed.
The NYT also reported that Sacks became close with Nvidia CEO Jensen Huang this spring and has played a role in removing restrictions on Nvidia chip sales around the world, including in China.
Right-wing media personality and former Trump adviser Steve Bannon (who’s made no secret of his animosity toward some of Trump’s Silicon Valley allies) said Sacks is emblematic of an administration where “the tech bros are out of control.”
Sacks’ spokesperson Jessica Hoffman told the NYT that “this conflict of interest narrative is false.” Hoffman said Sacks has complied with the rules for special government employees, that the Office of Government Ethics determined which investments he had to sell, and that his role in the government has cost him, rather than benefited him.
White House spokesperson Liz Huston said Sacks has been “an invaluable asset for President Trump’s agenda of cementing American technology dominance.”
Sacks’ post responding to the NYT includes a letter written to the newspaper from Clare Locke, a law firm that Sacks hired, claiming that the reporters had been given “clear marching orders: find and report on a conflict of interest between Mr. Sacks’ duties in the White House and his background in the private technology sector.”
The letter also addresses some of the specifics of the NYT story, including the All-In podcast’s role in the White House AI event. Sacks’ lawyers said the AI summit was a not-for-profit event, and that the All-In podcast “lost money hosting the event.”
“Two sponsors were brought on to help partially defray the cost of the event, for which they received nothing but logo placements,” the letter said. “No access to President Trump was ever offered, and no VIP reception ever took place.”
Finland’s weather is notoriously unfriendly; but even so, your food order might be delivered by a drone.
On a rainy day after Helsinki’s annual Slush conference, Finnish entrepreneur Ville Leppälä took TechCrunch behind the scenes of a three-party partnership between Irish drone delivery company Manna, DoorDash-owned food delivery platform Wolt, and his own startup, Huuva.
Huuva, whose name means kitchen hood, raised a seed round led by General Catalyst in 2022 with the promise of bringing good food to the suburbs. While it branched out of its cloud kitchen origins, its business still relies heavily on delivery tech — now including drones.
“If available, we’ll send your order with a drone.” That’s how Wolt has been notifying customers ordering from Huuva’s Niittari location in Espoo, which is part of the Helsinki metropolitan area, but which Leppälä sees as particularly well-suited for this concept.
While European suburbs aren’t as sprawling as those in the United States, people who work, study, and live in places like Espoo still lack the variety of options they can find in the capital. Huuva lets them order popular items from partner restaurant brands — and drones help those orders arrive faster, Leppälä said.
Building upon Manna’s track record of completing more than 50,000 deliveries in Dublin, operations in Finland started quickly once the appropriate permits were secured. After a pilot phase from February, the drones have been fully operational for the last two months in Espoo, where they depart from a launchpad that’s shared with delivery-only grocery store Wolt Market.
For the end users, this means that they can order different food styles from Huuva’s partner brands, and add some groceries, too — each drone can carry around 4.4 pounds, and Manna can send two of them at once.
This adds another layer of convenience, but also speed. Unlike drivers, drones won’t get stuck in traffic at lunch time. According to Leppälä, this is key to making sure the food arrives fresh; and it doesn’t hurt if unit economics are more sustainable for Huuva, too.
Huuva’s team estimates that regular deliveries currently cost €5-6 each (approximately $6-8), while drone deliveries could get down to €1 ($1.16). That’s not accounting for the extra costs that Manna may be incurring from setting up its Finnish operations, although the weather wasn’t as challenging as it might have been for a newcomer.
Coming from Ireland, Manna’s drones were already thoroughly tested for wind and rain, in such quantities that snow also falls under the same umbrella. Icing does present an extra challenge, but according to local operations and maintenance lead Makar Nalimov, in those cases they’ll just use other delivery methods, especially since using chemicals for de-icing is also out of the question when food is involved.
These fallback options highlight that Manna’s drones are part of a fast-expanding range of last-mile delivery solutions. Wolt itself is already using sidewalk robots from Coco and Starship in Finland, and its parent company DoorDash even built its own, Dot, which started performing deliveries in Arizona earlier this year.
Amid rumors that DoorDash may be building its own drone delivery program, in addition to collaborating with Alphabet-owned Wing, direct partnerships could be beneficial to companies like Manna and Huuva. The food startup is considering an expansion to another Espoo location where Wolt Market would be out of the equation, which would make it possible for the launchpad to be close enough to the kitchen for deliveries to be handed over through a window.
In the current process, Manna’s launchpad sits within a short distance; delivery workers on e-scooters pick up the orders from the kitchen in a heat bag, then carry it over to Manna’s operators. Under maintenance lead Nalimov’s supervision, they put the orders on a scale and balance the weight if needed before placing them into special bags approved by regulators.
Resistant bags are only one of many safety measures that Manna follows to comply with regulations and its own procedures. For instance, batteries are systematically swapped so that drones always fly with a full charge. According to Nalimov, there’s also redundancy at all levels, plus preparedness for different incident scenarios — and a parachute as a last resort.
Although Manna has staff on the ground, Mission Control sits in Ireland. There, operators assess the lidar maps, review the planned flight itinerary, and drop a pin for the drone to deliver within a short radius of the customer’s location. If conditions aren’t met, the order falls back to a courier. If approved, the drone captures an image of the landing spot for final human confirmation before lowering the package with biodegradable rope.
This process has now become routine for Manna’s local staff, which is getting busier. According to Nalimov, he and his team are now handling double-digit deliveries a day, and are confidently gearing up for their first operational winter in Finland. As for Huuva, it is now ready to double down on drone deliveries in Espoo, with one extra wish: being allowed to put its logo on those regulator-sanctioned bags.
Flights were delayed and cancelled globally after Airbus ordered fixes to 6,000 of its A320 series planes, according to The Guardian.
The company said it’s taking action because “analysis of a recent event involving an A320 Family aircraft has revealed that intense solar radiation may corrupt data critical to the functioning of flight controls.”
Citing industry sources, Reuters reports that the event in question was an October 30 JetBlue flight from Cancun, Mexico to Newark, New Jersey, in which the plane suddenly lost altitude and had to make an emergency landing in Tampa.
The Federal Aviation Administration has reportedly issued an emergency airworthiness directive calling for the affected planes to revert to earlier software before they can fly again. A smaller subset will need to have their hardware changed, Airbus said.
New York’s latest state budget includes new disclosure requirements for businesses that use personal data to set different prices for different shoppers — for example, charging you more if you have a history of splurging.
Businesses that use personalized pricing are now required to tell customers, “This price was set by an algorithm using your personal data,” according to The New York Times.
It’s not clear how widespread this practice actually is among online retailers. An Uber spokesperson told the NYT that the company is now showing this disclosure to New Yorkers, although they described the law as “poorly drafted and ambiguous” and insisted that Uber only uses geography and customer demand to calculate its dynamic pricing.
The National Retail Federation filed a lawsuit to stop the law, but a federal judge allowed it to move forward.
Lina Khan, former chair of the Federal Trade Commission and now co-chair of the mayoral transition team for Zohran Mamdani, told the NYT that the law will be an “absolutely vital” tool for the government, but she also suggested there’s a “ton more work to be done” to regulate the practice.
Meesho, an Indian e-commerce rival to Amazon and Walmart-owned Flipkart, is set to launch a roughly $606 million IPO marked by token sell-downs from early backers and no sales from big names such as SoftBank and Prosus, signaling investor conviction in India’s booming online retail market at a time when tech shareholders globally have been cashing out at listings.
The 10-year-old startup plans to price its shares at ₹105 to ₹111 each, raising ₹42.50 billion (about $475 million) in fresh capital and a small remainder through secondary sales, giving Meesho a post-issue valuation of roughly ₹501 billion (around $5.60 billion). The startup was last valued at about $5 billion in the private markets in 2021.
Meesho is set to become the first major horizontal e-commerce platform in India to go public, with rival Flipkart expected to pursue an IPO next year and Amazon reportedly exploring a potential spin-off of its India operations, potentially for a future listing.
Some of Meesho’s early shareholders are selling in the IPO, with Elevation Capital offloading just over 4% of its stake, Sequoia Capital spin-off Peak XV Partners selling around 3%, and Y Combinator trimming about 14%, per the prospectus (PDF). Larger backers — including SoftBank, Prosus, and Fidelity — are not selling any shares.
Meesho’s offer-for-sale portion has been cut by about 40% from the draft prospectus filed in October to 105.5 million shares, worth ₹11.7 billion (roughly $131 million) at the top of the price band. The co-founders, Vidit Aatrey and Sanjeev Kumar, are, however, selling more than they had planned in the draft prospectus, with their combined offer rising to 32 million shares from about 23.5 million earlier, helping make up for reduced participation from other shareholders.
Founded in 2015, Meesho began as a social commerce platform that targeted first-time online shoppers through WhatsApp before evolving into a full-fledged marketplace. It has since carved out a fast-growing niche with a low-cost model tailored to India’s price-sensitive consumers and small merchants — an approach that has increasingly pressured larger rivals Amazon and Flipkart. The Bengaluru-based company uses a commission-light model, earning primarily from logistics fees, advertising, and other services, while charging commissions on products sold through its separate Meesho Mall channel.
Meesho reported revenue from operations of ₹55.78 billion (about $624.0 million) for the six months ended September 30, up from ₹43.11 billion (around $482.0 million) a year earlier, per its prospectus. Net merchandise value rose 44% year-over-year to ₹191.94 billion (roughly $2.15 billion). However, its losses widened, with Meesho posting a restated loss before tax of ₹4.33 billion (around $48.4 million) for the September 2025 half-year, compared with ₹0.24 billion (about $2.7 million) a year earlier.
In the last 12 months, Meesho recorded 234.20 million transacting users — unique consumers who purchased at least one product on the platform. Over the same period, the company had 706,471 annual transacting sellers, defined as sellers who received at least one order in the year.
Meesho also uses a sprawling creator network for product discovery, with more than 50,000 active content creators generating at least one placed order through their content over the past year.
“Many Indians are only experiencing e-commerce for the first time on Meesho, and much like the rest of us, over the next decade, they will buy more and more things and more and more frequently on this platform,” Mohit Bhatnagar, managing director at Peak XV Partners, told TechCrunch. “That’s why long-term conviction is the reason to hold on to as much of our stake as we can hold on to.”
Peak XV — which first invested in Meesho in 2018 during its Sequoia Capital India era and holds about 13% across its two vehicles — is selling around 17.38 million shares in the IPO.
Meesho has positioned itself as a value-focused platform — unlike Amazon and Flipkart, which it sees as convenience-led players. In that respect, the company compares itself with other value-driven marketplaces such as Pinduoduo in China, Shopee in Southeast Asia, and Mercado Libre in Latin America.
“If you look at the value-focused bucket, here, you are trying to appeal to mass market consumers selling all kinds of products and categories in a marketplace business model, which tends to be asset light,” Aatrey told reporters during Meesho’s press conference on Friday. “And the reason people come back is because they want access to more and more selection with the affordability value proposition.”
Meesho also sees the IPO improving its ability to attract talent and strengthening confidence across its wider ecosystem, CFO Dhiresh Bansal told TechCrunch. He said a public listing boosts the company’s brand with job candidates — including those coming from Big Tech firms — and has a positive knock-on effect on consumers, sellers, and logistics partners by reinforcing Meesho’s governance standards.
The IPO will open for public subscription on December 3, with the anchor book scheduled for December 2. About 75% of the offer is reserved for qualified institutional buyers, 10% for retail investors, and 15% for non-institutional investors.
